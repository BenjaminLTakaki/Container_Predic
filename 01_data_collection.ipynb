{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9810d2ed",
   "metadata": {},
   "source": [
    "# Data Collection for Europe Base Port Container Price Prediction\n",
    "\n",
    "This notebook focuses on gathering all the raw data needed for our 1-week ahead container price forecasting project. We will collect data from three different sources and save it for later processing.\n",
    "\n",
    "## What is data collection?\n",
    "\n",
    "Data collection is the first step in any data science project. It involves gathering raw information from various sources like files, databases, or APIs (Application Programming Interfaces, which are ways for programs to talk to each other over the internet). Think of it like gathering ingredients before cooking a meal.\n",
    "\n",
    "## What are we predicting?\n",
    "\n",
    "**Target**: Europe Base Port container prices (1 week ahead)\n",
    "\n",
    "**Base Ports Definition**: Average shipping cost for a 40-foot container from Shanghai/China to major European ports including Rotterdam (Netherlands), Hamburg (Germany), London (UK), and Antwerp (Belgium).\n",
    "\n",
    "**Why these ports**: These represent the main entry points for Asian goods into Europe and provide a standard benchmark for European route pricing.\n",
    "\n",
    "## Our data sources:\n",
    "\n",
    "1. Shanghai Containerized Freight Index (local CSV file) - Main price data\n",
    "2. Oil prices (from Yahoo Finance API Hopefully) - Cost factor affecting shipping / (Not working looking for work around)\n",
    "3. Geopolitical disruption data (from GDELT via BigQuery) - Black swan event indicators\n",
    "\n",
    "**Note**: We use GDELT data exported from Google BigQuery for historical coverage (2018-2025). This provides weekly disruption metrics including conflict events, severe incidents, and sentiment analysis for shipping-critical regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b80a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc6a28",
   "metadata": {},
   "source": [
    "## Step 1: Load the Shanghai Containerized Freight Index\n",
    "\n",
    "This is our main dataset. It contains weekly freight prices for shipping containers from Shanghai to various destinations around the world. We are specifically interested in the Europe Base Port price, which represents the average cost to ship a container from Shanghai/China to major European ports (Rotterdam, Hamburg, London, Antwerp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbad2e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the CSV file with 385 rows and 5 columns\n",
      "\n",
      "First 5 rows of the raw data:\n",
      "  the period (YYYY-MM-DD)  Comprehensive Index  Europe (Base port)  \\\n",
      "0                1/5/2018               816.58                 888   \n",
      "1               1/12/2018               839.72                 897   \n",
      "2               1/19/2018               840.36                 891   \n",
      "3               1/26/2018               858.60                 907   \n",
      "4                2/2/2018               883.59                 912   \n",
      "\n",
      "   Mediterranean (Base port)  Persian Gulf and Red Sea (Dubai)  \n",
      "0                        738                               433  \n",
      "1                        759                               450  \n",
      "2                        761                               572  \n",
      "3                        772                               631  \n",
      "4                        797                               611  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load the raw CSV file\n",
    "    # header=1 means the actual column names are in the second row (row 1, counting from 0)\n",
    "    raw_df = pd.read_csv('data/Shanghai_Containerized_Freight_Index.csv', header=1)\n",
    "    print(f\"Successfully loaded the CSV file with {raw_df.shape[0]} rows and {raw_df.shape[1]} columns\")\n",
    "    \n",
    "    # Display the first few rows to see what the data looks like\n",
    "    print(\"\\nFirst 5 rows of the raw data:\")\n",
    "    print(raw_df.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'data/Shanghai_Containerized_Freight_Index.csv' was not found.\")\n",
    "    print(\"Please make sure it is in the data folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a052b",
   "metadata": {},
   "source": [
    "## Step 2: Select and rename the columns we need\n",
    "\n",
    "The dataset has many columns for different routes, but we only need a few for our Europe Base Port prediction. We will select the date column, the overall freight index (SCFI), and the Europe Base Port price.\n",
    "\n",
    "### Why select only these columns?\n",
    "\n",
    "Europe Base Port: Our prediction target - average cost from Shanghai to Rotterdam/Hamburg/London/Antwerp\n",
    "\n",
    "SCFI_Index: Overall freight market indicator (note: highly correlated with Europe prices, so we may exclude it from final models)\n",
    "\n",
    "Date: Needed for time series analysis and chronological ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e456b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected and renamed columns:\n",
      "['Date', 'SCFI_Index', 'Europe_Base_Price']\n",
      "\n",
      "Dataset now has 385 rows and 3 columns\n",
      "\n",
      "First 5 rows:\n",
      "        Date  SCFI_Index  Europe_Base_Price\n",
      "0   1/5/2018      816.58                888\n",
      "1  1/12/2018      839.72                897\n",
      "2  1/19/2018      840.36                891\n",
      "3  1/26/2018      858.60                907\n",
      "4   2/2/2018      883.59                912\n"
     ]
    }
   ],
   "source": [
    "# Select only the columns we need\n",
    "df_freight = raw_df[['the period (YYYY-MM-DD)', 'Comprehensive Index', 'Europe (Base port)']].copy()\n",
    "\n",
    "# Rename columns to simpler names\n",
    "df_freight.columns = ['Date', 'SCFI_Index', 'Europe_Base_Price']\n",
    "\n",
    "print(\"Selected and renamed columns:\")\n",
    "print(df_freight.columns.tolist())\n",
    "print(f\"\\nDataset now has {df_freight.shape[0]} rows and {df_freight.shape[1]} columns\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_freight.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defbac9f",
   "metadata": {},
   "source": [
    "## Step 3: Convert date strings to proper date format\n",
    "\n",
    "Right now, the Date column is just text. We need to convert it to a proper datetime format so Python understands it represents actual dates.\n",
    "\n",
    "### What is datetime?\n",
    "\n",
    "datetime is a special data type in Python that represents dates and times. It allows us to do things like sort by date, calculate time differences, and extract parts of a date (like the month or year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8401c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted 385 out of 385 dates\n",
      "After removing invalid dates: 385 rows remaining\n",
      "\n",
      "Date conversion complete!\n",
      "            SCFI_Index  Europe_Base_Price\n",
      "Date                                     \n",
      "2018-01-05      816.58                888\n",
      "2018-01-12      839.72                897\n",
      "2018-01-19      840.36                891\n",
      "2018-01-26      858.60                907\n",
      "2018-02-02      883.59                912\n"
     ]
    }
   ],
   "source": [
    "df_freight['Date'] = pd.to_datetime(df_freight['Date'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Check how many dates were successfully converted\n",
    "valid_dates = df_freight['Date'].notna().sum()\n",
    "total_rows = len(df_freight)\n",
    "print(f\"Successfully converted {valid_dates} out of {total_rows} dates\")\n",
    "\n",
    "# Remove rows where date conversion failed\n",
    "df_freight.dropna(subset=['Date'], inplace=True)\n",
    "print(f\"After removing invalid dates: {len(df_freight)} rows remaining\")\n",
    "\n",
    "# Set the Date column as the index (the row identifier)\n",
    "df_freight.set_index('Date', inplace=True)\n",
    "\n",
    "print(\"\\nDate conversion complete!\")\n",
    "print(df_freight.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5391d",
   "metadata": {},
   "source": [
    "## Step 4: Convert price columns to numbers\n",
    "\n",
    "Sometimes data is read as text even when it represents numbers. We need to ensure our price columns are in numeric format so we can do calculations with them.\n",
    "\n",
    "### What is numeric conversion?\n",
    "\n",
    "This process takes text that looks like numbers (like \"123.45\") and converts it to actual numbers that Python can use for math operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c89d515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted SCFI_Index to numeric type\n",
      "Converted Europe_Base_Price to numeric type\n",
      "\n",
      "Removed 0 rows with missing values\n",
      "Final freight dataset: 385 rows\n",
      "Date range: 2018-01-05 to 2025-08-22\n",
      "\n",
      "Final cleaned freight data:\n",
      "            SCFI_Index  Europe_Base_Price\n",
      "Date                                     \n",
      "2018-01-05      816.58                888\n",
      "2018-01-12      839.72                897\n",
      "2018-01-19      840.36                891\n",
      "2018-01-26      858.60                907\n",
      "2018-02-02      883.59                912\n"
     ]
    }
   ],
   "source": [
    "# Convert price columns to numeric format\n",
    "for col in ['SCFI_Index', 'Europe_Base_Price']:\n",
    "    df_freight[col] = pd.to_numeric(df_freight[col], errors='coerce')\n",
    "    print(f\"Converted {col} to numeric type\")\n",
    "\n",
    "# Remove any rows with missing values\n",
    "# This ensures we have complete data for all rows\n",
    "before_drop = len(df_freight)\n",
    "df_freight.dropna(inplace=True)\n",
    "after_drop = len(df_freight)\n",
    "\n",
    "print(f\"\\nRemoved {before_drop - after_drop} rows with missing values\")\n",
    "print(f\"Final freight dataset: {after_drop} rows\")\n",
    "print(f\"Date range: {df_freight.index.min().strftime('%Y-%m-%d')} to {df_freight.index.max().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "print(\"\\nFinal cleaned freight data:\")\n",
    "print(df_freight.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d81295",
   "metadata": {},
   "source": [
    "## Step 5: Fetch oil price data\n",
    "\n",
    "Oil prices affect shipping costs since ships use fuel. We will download historical oil prices using multiple fallback methods.\n",
    "\n",
    "### Option 1: Yahoo Finance API (Primary)\n",
    "\n",
    "We try to fetch data from Yahoo Finance using the `yfinance` library. This is free and usually reliable, though it can occasionally fail due to rate limiting or API changes.\n",
    "\n",
    "**Tickers tried:**\n",
    "- **USO**: United States Oil Fund ETF (most reliable)\n",
    "- **CL=F**: WTI Crude Oil Futures\n",
    "- **BZ=F**: Brent Crude Oil Futures  \n",
    "- **XLE**: Energy Select Sector SPDR Fund (energy sector)\n",
    "\n",
    "### Option 2: Manual CSV File (Backup)\n",
    "\n",
    "If Yahoo Finance fails, you can provide your own oil price data:\n",
    "\n",
    "1. **Download oil prices** from one of these sources:\n",
    "   - **EIA (U.S. Energy Information Administration)**: https://www.eia.gov/dnav/pet/hist/RWTCD.htm\n",
    "     - Free, official U.S. government data\n",
    "     - Download as Excel/CSV and save as `oil_prices_manual.csv`\n",
    "   - **FRED (Federal Reserve Economic Data)**: https://fred.stlouisfed.org/series/DCOILWTICO\n",
    "     - Free historical WTI crude oil prices\n",
    "     - Click \"Download\" â†’ CSV format\n",
    "   - **Quandl/Nasdaq Data Link**: https://data.nasdaq.com/\n",
    "     - Free tier available with API key\n",
    "     \n",
    "2. **Format the CSV** with two columns:\n",
    "   ```\n",
    "   Date,Price\n",
    "   2018-01-01,60.37\n",
    "   2018-01-02,61.44\n",
    "   ...\n",
    "   ```\n",
    "   \n",
    "3. **Save as** `oil_prices_manual.csv` in the same directory as this notebook\n",
    "\n",
    "### Option 3: Synthetic Data (Last Resort)\n",
    "\n",
    "If no real data is available, we create synthetic oil prices for testing purposes only. This uses a random walk model with realistic price ranges ($50-$120) but should NOT be used for actual predictions.\n",
    "\n",
    "### Why Brent/WTI Crude Oil?\n",
    "\n",
    "Brent Crude and WTI (West Texas Intermediate) are major oil benchmarks used for global pricing. Their price movements indicate changes in shipping fuel costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35447936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FETCHING OIL/ENERGY PRICE DATA\n",
      "======================================================================\n",
      "\n",
      "Requesting data from 2018-01-05 to 2025-08-22\n",
      "\n",
      "--- Option 1: Trying Yahoo Finance API ---\n",
      "\n",
      "Trying United States Oil Fund ETF (USO)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'USO' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['USO']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n",
      "\n",
      "1 Failed download:\n",
      "['USO']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No data or insufficient data returned for USO\n",
      "\n",
      "Trying WTI Crude Oil Futures (CL=F)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'CL=F' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['CL=F']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n",
      "\n",
      "1 Failed download:\n",
      "['CL=F']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No data or insufficient data returned for CL=F\n",
      "\n",
      "Trying Brent Crude Oil Futures (BZ=F)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'BZ=F' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "['BZ=F']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n",
      "\n",
      "1 Failed download:\n",
      "['BZ=F']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No data or insufficient data returned for BZ=F\n",
      "\n",
      "Trying Energy Select Sector SPDR Fund (XLE)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'XLE' reason: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "1 Failed download:\n",
      "\n",
      "1 Failed download:\n",
      "['XLE']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n",
      "['XLE']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No data or insufficient data returned for XLE\n",
      "\n",
      "--- Option 2: Trying manual CSV file ---\n",
      "Error: Manual CSV file not found: oil_prices_manual.csv\n",
      "\n",
      "--- Option 3: Creating synthetic placeholder data ---\n",
      "Warning: No real oil data available. Creating synthetic data for demonstration.\n",
      "This should only be used for testing. For production, obtain real oil price data.\n",
      "Success: Created 2787 days of synthetic oil price data\n",
      "  Date range: 2018-01-05 to 2025-08-22\n",
      "  Price range: $50.00 to $120.00\n",
      "  Average: $103.58\n",
      "\n",
      "Warning: This is SYNTHETIC data. Replace with real data for actual predictions.\n",
      "\n",
      "======================================================================\n",
      "OIL DATA COLLECTION COMPLETE\n",
      "======================================================================\n",
      "Total days: 2787\n",
      "Data source: Yahoo Finance\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FETCHING OIL/ENERGY PRICE DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get the date range from our freight data\n",
    "start_date = df_freight.index.min().strftime('%Y-%m-%d')\n",
    "end_date = df_freight.index.max().strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"\\nRequesting data from {start_date} to {end_date}\")\n",
    "\n",
    "df_oil = pd.DataFrame()\n",
    "\n",
    "# Option 1: Try Yahoo Finance first (most reliable when it works)\n",
    "print(\"\\n--- Option 1: Trying Yahoo Finance API ---\")\n",
    "\n",
    "oil_tickers = [\n",
    "    ('USO', 'United States Oil Fund ETF'),  # Oil ETF - most reliable\n",
    "    ('CL=F', 'WTI Crude Oil Futures'),  # WTI Futures\n",
    "    ('BZ=F', 'Brent Crude Oil Futures'),  # Brent Futures\n",
    "    ('XLE', 'Energy Select Sector SPDR Fund'),  # Energy sector ETF\n",
    "]\n",
    "\n",
    "for ticker, name in oil_tickers:\n",
    "    print(f\"\\nTrying {name} ({ticker})...\")\n",
    "    \n",
    "    try:\n",
    "        # Download the oil price data with a longer timeout\n",
    "        temp_df = yf.download(ticker, start=start_date, end=end_date, progress=False, timeout=15)\n",
    "\n",
    "        if not temp_df.empty and len(temp_df) > 10:  # Need at least some data\n",
    "            # Sometimes yfinance returns data with multiple column levels, we need to flatten it\n",
    "            if temp_df.columns.nlevels > 1:\n",
    "                temp_df.columns = temp_df.columns.droplevel(1)\n",
    "            \n",
    "            # Keep only the closing price and rename it\n",
    "            df_oil = temp_df[['Close']].rename(columns={'Close': 'Oil_Price'})\n",
    "            \n",
    "            print(f\"Success: Successfully fetched {len(df_oil)} days of oil price data from {name}\")\n",
    "            print(f\"  Date range: {df_oil.index.min().strftime('%Y-%m-%d')} to {df_oil.index.max().strftime('%Y-%m-%d')}\")\n",
    "            print(f\"  Price range: ${df_oil['Oil_Price'].min():.2f} to ${df_oil['Oil_Price'].max():.2f}\")\n",
    "            print(f\"  Average price: ${df_oil['Oil_Price'].mean():.2f}\")\n",
    "            print(\"\\nFirst 5 rows of oil data:\")\n",
    "            print(df_oil.head())\n",
    "            break  # Success! Exit the loop\n",
    "        else:\n",
    "            print(f\"Error: No data or insufficient data returned for {ticker}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: Error with {ticker}: {str(e)[:150]}\")\n",
    "        continue\n",
    "\n",
    "# Option 2: Try loading from a manual CSV file if API failed\n",
    "if df_oil.empty:\n",
    "    print(\"\\n--- Option 2: Trying manual CSV file ---\")\n",
    "    try:\n",
    "        # Check if user has provided a manual oil price CSV\n",
    "        oil_csv_path = 'oil_prices_manual.csv'\n",
    "        df_oil = pd.read_csv(oil_csv_path, parse_dates=['Date'], index_col='Date')\n",
    "        \n",
    "        # Filter to our date range\n",
    "        df_oil = df_oil[(df_oil.index >= start_date) & (df_oil.index <= end_date)]\n",
    "        \n",
    "        if not df_oil.empty:\n",
    "            # Rename to standard column name\n",
    "            if 'Price' in df_oil.columns:\n",
    "                df_oil = df_oil[['Price']].rename(columns={'Price': 'Oil_Price'})\n",
    "            elif 'Close' in df_oil.columns:\n",
    "                df_oil = df_oil[['Close']].rename(columns={'Close': 'Oil_Price'})\n",
    "            \n",
    "            print(f\"Success: Loaded {len(df_oil)} days from manual CSV: {oil_csv_path}\")\n",
    "            print(f\"  Date range: {df_oil.index.min().strftime('%Y-%m-%d')} to {df_oil.index.max().strftime('%Y-%m-%d')}\")\n",
    "            print(f\"  Price range: ${df_oil['Oil_Price'].min():.2f} to ${df_oil['Oil_Price'].max():.2f}\")\n",
    "        else:\n",
    "            print(f\"Error: CSV file found but no data in date range\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Manual CSV file not found: {oil_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Error loading manual CSV: {str(e)[:100]}\")\n",
    "\n",
    "# Option 3: Create synthetic oil price data based on historical patterns (last resort)\n",
    "if df_oil.empty:\n",
    "    print(\"\\n--- Option 3: Creating synthetic placeholder data ---\")\n",
    "    print(\"Warning: No real oil data available. Creating synthetic data for demonstration.\")\n",
    "    print(\"This should only be used for testing. For production, obtain real oil price data.\")\n",
    "    \n",
    "    # Create date range matching freight data\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    \n",
    "    # Create synthetic oil prices with realistic values and volatility\n",
    "    # Base price around $70-80 with random walk\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    base_price = 75.0\n",
    "    random_walk = np.random.randn(len(date_range)).cumsum() * 2  # Random walk with std=2\n",
    "    synthetic_prices = base_price + random_walk\n",
    "    \n",
    "    # Clip to reasonable range (50-120)\n",
    "    synthetic_prices = np.clip(synthetic_prices, 50, 120)\n",
    "    \n",
    "    df_oil = pd.DataFrame({\n",
    "        'Oil_Price': synthetic_prices\n",
    "    }, index=date_range)\n",
    "    \n",
    "    print(f\"Success: Created {len(df_oil)} days of synthetic oil price data\")\n",
    "    print(f\"  Date range: {df_oil.index.min().strftime('%Y-%m-%d')} to {df_oil.index.max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  Price range: ${df_oil['Oil_Price'].min():.2f} to ${df_oil['Oil_Price'].max():.2f}\")\n",
    "    print(f\"  Average: ${df_oil['Oil_Price'].mean():.2f}\")\n",
    "    print(\"\\nWarning: This is SYNTHETIC data. Replace with real data for actual predictions.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"OIL DATA COLLECTION COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total days: {len(df_oil)}\")\n",
    "print(f\"Data source: {'Yahoo Finance' if not df_oil.empty and 'synthetic' not in str(df_oil.index.name) else 'Synthetic/Manual'}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f759cc",
   "metadata": {},
   "source": [
    "## Step 6: Load the new \"black swan\" geopolitical disruption data\n",
    "\n",
    "We now load the new, richer BigQuery dataset that contains specific geopolitical and black swan event metrics for shipping-critical regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b00bcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING NEW BLACK SWAN GEOPOLITICAL DISRUPTION DATA\n",
      "======================================================================\n",
      "Success: Loaded 414 weekly records from data/bq-results-20251021-090045-1761037274833.csv\n",
      "  Columns: ['iso_year', 'week', 'global_total_events', 'global_disruption_events', 'extreme_crisis_events', 'high_velocity_media_events', 'black_swan_candidate_events', 'global_avg_impact', 'global_worst_event_impact', 'global_avg_sentiment', 'global_total_media_mentions', 'global_peak_event_media', 'maritime_conflict_events', 'infrastructure_attack_events', 'trade_restriction_events', 'protest_events', 'middle_east_disruption', 'asia_disruption', 'europe_disruption', 'russia_ukraine_disruption', 'egypt_disruption', 'yemen_disruption', 'unique_sources']\n",
      "Removed 7 week 53 entries (invalid weeks)\n",
      "\n",
      "Converting ISO week numbers to Friday dates...\n",
      "Success: Converted dates. New range: 2018-01-05 to 2025-10-24\n",
      "Success: Dropped 'global_worst_event_impact' column.\n",
      "\n",
      "Success: New black swan data saved to 'collected_news_data.csv'\n",
      "   Contains 22 predictive features.\n",
      "\n",
      "Sample of new event data:\n",
      "            iso_year  week  global_total_events  global_disruption_events  \\\n",
      "date                                                                        \n",
      "2018-01-05      2018     1              1472667                    428017   \n",
      "2018-01-12      2018     2              1839672                    501432   \n",
      "2018-01-19      2018     3              1945383                    530159   \n",
      "2018-01-26      2018     4              1964751                    527932   \n",
      "2018-02-02      2018     5              1872867                    507981   \n",
      "\n",
      "            extreme_crisis_events  high_velocity_media_events  \\\n",
      "date                                                            \n",
      "2018-01-05                 130616                         218   \n",
      "2018-01-12                 146603                         245   \n",
      "2018-01-19                 160491                         283   \n",
      "2018-01-26                 157314                         287   \n",
      "2018-02-02                 154738                         315   \n",
      "\n",
      "            black_swan_candidate_events  global_avg_impact  \\\n",
      "date                                                         \n",
      "2018-01-05                           23           0.373966   \n",
      "2018-01-12                           33           0.566314   \n",
      "2018-01-19                           25           0.546652   \n",
      "2018-01-26                           23           0.581645   \n",
      "2018-02-02                           28           0.549771   \n",
      "\n",
      "            global_avg_sentiment  global_total_media_mentions  ...  \\\n",
      "date                                                           ...   \n",
      "2018-01-05             -2.220817                      8890512  ...   \n",
      "2018-01-12             -1.967170                     11070095  ...   \n",
      "2018-01-19             -1.945620                     11624467  ...   \n",
      "2018-01-26             -1.849213                     11704774  ...   \n",
      "2018-02-02             -1.962496                     11366976  ...   \n",
      "\n",
      "            infrastructure_attack_events  trade_restriction_events  \\\n",
      "date                                                                 \n",
      "2018-01-05                          2289                     94104   \n",
      "2018-01-12                          2674                    111365   \n",
      "2018-01-19                          3037                    112691   \n",
      "2018-01-26                          3168                    113725   \n",
      "2018-02-02                          3465                    110930   \n",
      "\n",
      "            protest_events  middle_east_disruption  asia_disruption  \\\n",
      "date                                                                  \n",
      "2018-01-05           19194                   44959             7733   \n",
      "2018-01-12           19339                   36202             9490   \n",
      "2018-01-19           20796                   30938            10294   \n",
      "2018-01-26           21328                   24935             9130   \n",
      "2018-02-02           17497                   27902             9456   \n",
      "\n",
      "            europe_disruption  russia_ukraine_disruption  egypt_disruption  \\\n",
      "date                                                                         \n",
      "2018-01-05               6521                      16525              5178   \n",
      "2018-01-12               7895                      22687              5479   \n",
      "2018-01-19               8486                      23080              5298   \n",
      "2018-01-26               9574                      24938              4537   \n",
      "2018-02-02               8531                      27423              4154   \n",
      "\n",
      "            yemen_disruption  unique_sources  \n",
      "date                                          \n",
      "2018-01-05              3215          447836  \n",
      "2018-01-12              2988          555780  \n",
      "2018-01-19              2826          569161  \n",
      "2018-01-26              2781          568662  \n",
      "2018-02-02              3544          559647  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"LOADING NEW BLACK SWAN GEOPOLITICAL DISRUPTION DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Helper function to convert ISO year/week to Friday date\n",
    "def iso_to_friday_date(row):\n",
    "    \"\"\"Converts ISO year and week to the Friday of that week.\"\"\"\n",
    "    return datetime.fromisocalendar(int(row['iso_year']), int(row['week']), 5)\n",
    "\n",
    "# Load the new BigQuery export\n",
    "try:\n",
    "    news_file_path = 'data/bq-results-20251021-090045-1761037274833.csv'\n",
    "    df_news_raw = pd.read_csv(news_file_path)\n",
    "    print(f\"Success: Loaded {len(df_news_raw)} weekly records from {news_file_path}\")\n",
    "    print(f\"  Columns: {df_news_raw.columns.tolist()}\")\n",
    "\n",
    "    # Remove week 53 entries as they cause invalid week errors\n",
    "    before_filter = len(df_news_raw)\n",
    "    df_news_raw = df_news_raw[df_news_raw['week'] != 53]\n",
    "    after_filter = len(df_news_raw)\n",
    "    if before_filter != after_filter:\n",
    "        print(f\"Removed {before_filter - after_filter} week 53 entries (invalid weeks)\")\n",
    "\n",
    "    # Convert ISO week to Friday date to match freight data\n",
    "    print(\"\\nConverting ISO week numbers to Friday dates...\")\n",
    "    df_news_raw['date'] = df_news_raw.apply(iso_to_friday_date, axis=1)\n",
    "    df_news_raw['date'] = pd.to_datetime(df_news_raw['date'])\n",
    "    df_news_raw.set_index('date', inplace=True)\n",
    "    print(f\"Success: Converted dates. New range: {df_news_raw.index.min().date()} to {df_news_raw.index.max().date()}\")\n",
    "\n",
    "    # Drop the non-predictive global_worst_event_impact column\n",
    "    if 'global_worst_event_impact' in df_news_raw.columns:\n",
    "        df_news_raw = df_news_raw.drop(columns=['global_worst_event_impact'])\n",
    "        print(\"Success: Dropped 'global_worst_event_impact' column.\")\n",
    "\n",
    "    # Save the cleaned data\n",
    "    df_news_raw.to_csv('collected_news_data.csv')\n",
    "    print(f\"\\nSuccess: New black swan data saved to 'collected_news_data.csv'\")\n",
    "    print(f\"   Contains {len(df_news_raw.columns)} predictive features.\")\n",
    "    print(\"\\nSample of new event data:\")\n",
    "    print(df_news_raw.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{news_file_path}' was not found.\")\n",
    "    print(\"Please ensure the BigQuery export CSV file is in the data folder.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0fa59f",
   "metadata": {},
   "source": [
    "## Step 7: Save the collected data\n",
    "\n",
    "We will save all three datasets as CSV files so we can use them in the next notebooks without having to fetch the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b011a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved freight data to 'collected_freight_data.csv'\n",
      "  385 weekly records\n",
      "Saved oil price data to 'collected_oil_data.csv'\n",
      "  2787 daily records\n",
      "\n",
      "======================================================================\n",
      "DATA COLLECTION COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Summary of collected data:\n",
      "Available: Freight data: 385 weeks (2018-01-05 to 2025-08-22)\n",
      "Available: Oil data: 2787 days\n",
      "Available: Black swan disruption data: 407 weeks\n",
      "  Features: iso_year, week, global_total_events, global_disruption_events, extreme_crisis_events, high_velocity_media_events, black_swan_candidate_events, global_avg_impact, global_avg_sentiment, global_total_media_mentions, global_peak_event_media, maritime_conflict_events, infrastructure_attack_events, trade_restriction_events, protest_events, middle_east_disruption, asia_disruption, europe_disruption, russia_ukraine_disruption, egypt_disruption, yemen_disruption, unique_sources\n",
      "\n",
      "Ready for Step 2: Data Understanding and Feature Engineering\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save freight data\n",
    "df_freight.to_csv('collected_freight_data.csv')\n",
    "print(\"Saved freight data to 'collected_freight_data.csv'\")\n",
    "print(f\"  {len(df_freight)} weekly records\")\n",
    "\n",
    "# Save oil data if we have it\n",
    "if 'df_oil' in globals() and not df_oil.empty:\n",
    "    df_oil.to_csv('collected_oil_data.csv')\n",
    "    print(\"Saved oil price data to 'collected_oil_data.csv'\")\n",
    "    print(f\"  {len(df_oil)} daily records\")\n",
    "else:\n",
    "    print(\"No oil data to save (Yahoo Finance may be temporarily unavailable or df_oil not defined)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATA COLLECTION COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nSummary of collected data:\")\n",
    "print(f\"Available: Freight data: {len(df_freight)} weeks ({df_freight.index.min().strftime('%Y-%m-%d')} to {df_freight.index.max().strftime('%Y-%m-%d')})\")\n",
    "print(f\"Available: Oil data: {len(df_oil) if 'df_oil' in globals() and not df_oil.empty else 0} days\")\n",
    "\n",
    "# Black swan disruption data may not exist if the file failed to load; guard against NameError\n",
    "if 'df_news_raw' in globals():\n",
    "    try:\n",
    "        print(f\"Available: Black swan disruption data: {len(df_news_raw)} weeks\")\n",
    "        print(f\"  Features: {', '.join(df_news_raw.columns.tolist())}\")\n",
    "    except Exception:\n",
    "        # If df_news_raw exists but isn't a dataframe or has issues, report its type\n",
    "        print(f\"df_news_raw exists but could not be summarized (type={type(df_news_raw)})\")\n",
    "else:\n",
    "    print(\"Available: Black swan disruption data: 0 weeks (df_news_raw not found)\")\n",
    "\n",
    "print(\"\\nReady for Step 2: Data Understanding and Feature Engineering\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
