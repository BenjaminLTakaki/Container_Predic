{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9810d2ed",
   "metadata": {},
   "source": [
    "# Data Collection for Europe Base Port Container Price Prediction\n",
    "\n",
    "This notebook focuses on gathering all the raw data needed for our 1-week ahead container price forecasting project. We will collect data from three different sources and save it for later processing.\n",
    "\n",
    "## What are we predicting?\n",
    "\n",
    "**Target**: Europe Base Port container prices (1 week ahead)\n",
    "\n",
    "**Base Ports Definition**: Average shipping cost for a 40-foot container from Shanghai/China to major European ports including Rotterdam (Netherlands), Hamburg (Germany), London (UK), and Antwerp (Belgium).\n",
    "\n",
    "**Why these ports**: These represent the main entry points for Asian goods into Europe and provide a standard benchmark for European route pricing.\n",
    "\n",
    "## Our data sources:\n",
    "\n",
    "1. Shanghai Containerized Freight Index (local CSV file) - Main price data\n",
    "2. Crude oil prices (EIA DCOILWTICO dataset) - Cost factor affecting shipping fuel costs\n",
    "3. Geopolitical disruption data (from GDELT via BigQuery) - Black swan event indicators\n",
    "\n",
    "**Note**: We use GDELT data exported from Google BigQuery for historical coverage (2018-2025). This provides weekly disruption metrics including conflict events, severe incidents, and sentiment analysis for shipping-critical regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b80a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import plotly.express as px\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc6a28",
   "metadata": {},
   "source": [
    "## Step 1: Load the Shanghai Containerized Freight Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbad2e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the CSV file with 385 rows and 5 columns\n",
      "\n",
      "First 5 rows of the raw data:\n",
      "  the period (YYYY-MM-DD)  Comprehensive Index  Europe (Base port)  \\\n",
      "0                1/5/2018               816.58                 888   \n",
      "1               1/12/2018               839.72                 897   \n",
      "2               1/19/2018               840.36                 891   \n",
      "3               1/26/2018               858.60                 907   \n",
      "4                2/2/2018               883.59                 912   \n",
      "\n",
      "   Mediterranean (Base port)  Persian Gulf and Red Sea (Dubai)  \n",
      "0                        738                               433  \n",
      "1                        759                               450  \n",
      "2                        761                               572  \n",
      "3                        772                               631  \n",
      "4                        797                               611  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load the raw CSV file\n",
    "    # header=1 means the actual column names are in the second row (row 1, counting from 0)\n",
    "    raw_df = pd.read_csv('data/Shanghai_Containerized_Freight_Index.csv', header=1)\n",
    "    print(f\"Successfully loaded the CSV file with {raw_df.shape[0]} rows and {raw_df.shape[1]} columns\")\n",
    "    \n",
    "    # Display the first few rows to see what the data looks like\n",
    "    print(\"\\nFirst 5 rows of the raw data:\")\n",
    "    print(raw_df.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'data/Shanghai_Containerized_Freight_Index.csv' was not found.\")\n",
    "    print(\"Please make sure it is in the data folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a052b",
   "metadata": {},
   "source": [
    "## Step 2: Select and rename the columns we need\n",
    "\n",
    "The dataset has many columns for different routes, but we only need a few for our Europe Base Port prediction. We will select the date column, the overall freight index (SCFI), and the Europe Base Port price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1e456b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected and renamed columns:\n",
      "['Date', 'SCFI_Index', 'Europe_Base_Price']\n",
      "\n",
      "Dataset now has 385 rows and 3 columns\n",
      "\n",
      "First 5 rows:\n",
      "        Date  SCFI_Index  Europe_Base_Price\n",
      "0   1/5/2018      816.58                888\n",
      "1  1/12/2018      839.72                897\n",
      "2  1/19/2018      840.36                891\n",
      "3  1/26/2018      858.60                907\n",
      "4   2/2/2018      883.59                912\n"
     ]
    }
   ],
   "source": [
    "# Select only the columns we need\n",
    "df_freight = raw_df[['the period (YYYY-MM-DD)', 'Comprehensive Index', 'Europe (Base port)']].copy()\n",
    "\n",
    "# Rename columns to simpler names\n",
    "df_freight.columns = ['Date', 'SCFI_Index', 'Europe_Base_Price']\n",
    "\n",
    "print(\"Selected and renamed columns:\")\n",
    "print(df_freight.columns.tolist())\n",
    "print(f\"\\nDataset now has {df_freight.shape[0]} rows and {df_freight.shape[1]} columns\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_freight.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defbac9f",
   "metadata": {},
   "source": [
    "## Step 3: Convert date strings to proper date format\n",
    "\n",
    "Right now, the Date column is just text. We need to convert it to a proper datetime format so Python understands it represents actual dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8401c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted 385 out of 385 dates\n",
      "After removing invalid dates: 385 rows remaining\n",
      "\n",
      "Date conversion complete!\n",
      "            SCFI_Index  Europe_Base_Price\n",
      "Date                                     \n",
      "2018-01-05      816.58                888\n",
      "2018-01-12      839.72                897\n",
      "2018-01-19      840.36                891\n",
      "2018-01-26      858.60                907\n",
      "2018-02-02      883.59                912\n"
     ]
    }
   ],
   "source": [
    "df_freight['Date'] = pd.to_datetime(df_freight['Date'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Check how many dates were successfully converted\n",
    "valid_dates = df_freight['Date'].notna().sum()\n",
    "total_rows = len(df_freight)\n",
    "print(f\"Successfully converted {valid_dates} out of {total_rows} dates\")\n",
    "\n",
    "# Remove rows where date conversion failed\n",
    "df_freight.dropna(subset=['Date'], inplace=True)\n",
    "print(f\"After removing invalid dates: {len(df_freight)} rows remaining\")\n",
    "\n",
    "# Set the Date column as the index (the row identifier)\n",
    "df_freight.set_index('Date', inplace=True)\n",
    "\n",
    "print(\"\\nDate conversion complete!\")\n",
    "print(df_freight.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5391d",
   "metadata": {},
   "source": [
    "## Step 4: Convert price columns to numbers\n",
    "\n",
    "Sometimes data is read as text even when it represents numbers. We need to ensure our price columns are in numeric format so we can do calculations with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c89d515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted SCFI_Index to numeric type\n",
      "Converted Europe_Base_Price to numeric type\n",
      "\n",
      "Removed 0 rows with missing values\n",
      "Final freight dataset: 385 rows\n",
      "Date range: 2018-01-05 to 2025-08-22\n",
      "\n",
      "Final cleaned freight data:\n",
      "            SCFI_Index  Europe_Base_Price\n",
      "Date                                     \n",
      "2018-01-05      816.58                888\n",
      "2018-01-12      839.72                897\n",
      "2018-01-19      840.36                891\n",
      "2018-01-26      858.60                907\n",
      "2018-02-02      883.59                912\n"
     ]
    }
   ],
   "source": [
    "# Convert price columns to numeric format\n",
    "for col in ['SCFI_Index', 'Europe_Base_Price']:\n",
    "    df_freight[col] = pd.to_numeric(df_freight[col], errors='coerce')\n",
    "    print(f\"Converted {col} to numeric type\")\n",
    "\n",
    "# Remove any rows with missing values\n",
    "# This ensures we have complete data for all rows\n",
    "before_drop = len(df_freight)\n",
    "df_freight.dropna(inplace=True)\n",
    "after_drop = len(df_freight)\n",
    "\n",
    "print(f\"\\nRemoved {before_drop - after_drop} rows with missing values\")\n",
    "print(f\"Final freight dataset: {after_drop} rows\")\n",
    "print(f\"Date range: {df_freight.index.min().strftime('%Y-%m-%d')} to {df_freight.index.max().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "print(\"\\nFinal cleaned freight data:\")\n",
    "print(df_freight.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d81296",
   "metadata": {},
   "source": [
    "## Step 5: Time-Series Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c89d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main plot of Europe Base Port prices\n",
    "fig = px.line(df_freight, x=df_freight.index, y='Europe_Base_Price', title='Europe Base Port Container Prices (2018-2025)')\n",
    "fig.show()\n",
    "\n",
    "# Zoom in on COVID-19 port disruptions\n",
    "fig_covid = px.line(df_freight.loc['2020-01-01':'2022-12-31'], x=df_freight.loc['2020-01-01':'2022-12-31'].index, y='Europe_Base_Price', title='COVID-19 Port Disruptions Impact')\n",
    "fig_covid.show()\n",
    "\n",
    "# Zoom in on Suez Canal blockage\n",
    "fig_suez = px.line(df_freight.loc['2021-03-01':'2021-04-30'], x=df_freight.loc['2021-03-01':'2021-04-30'].index, y='Europe_Base_Price', title='Suez Canal Blockage Impact')\n",
    "fig_suez.show()\n",
    "\n",
    "# Zoom in on Red Sea crisis\n",
    "fig_red_sea = px.line(df_freight.loc['2023-10-01':], x=df_freight.loc['2023-10-01':].index, y='Europe_Base_Price', title='Red Sea Crisis Impact')\n",
    "fig_red_sea.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d81295",
   "metadata": {},
   "source": [
    "## Step 6: Load crude oil price data\n",
    "\n",
    "Oil prices affect shipping costs since ships use fuel. We will load historical crude oil prices from both EIA WTI and Brent EU datasets.\n",
    "\n",
    "### Data Sources: EIA DCOILWTICO and DCOILBRENTEU\n",
    "\n",
    "We use two major oil benchmarks from the U.S. Energy Information Administration (EIA):\n",
    "- **DCOILWTICO**: WTI (West Texas Intermediate) crude oil prices\n",
    "- **DCOILBRENTEU**: Brent EU crude oil prices\n",
    "\n",
    "**Files**: `data/DCOILWTICO.csv` and `data/DCOILBRENTEU.csv`\n",
    "**Format**: CSV with columns `observation_date` and price column\n",
    "**Frequency**: Daily prices\n",
    "\n",
    "### Why Both Oil Benchmarks?\n",
    "\n",
    "WTI and Brent are the two major global oil benchmarks. WTI is more US-focused while Brent is more representative of global oil prices. Including both provides a more comprehensive view of fuel cost fluctuations affecting shipping.\n",
    "\n",
    "### Processing Steps:\n",
    "1. Load both CSV files\n",
    "2. Convert dates to datetime format\n",
    "3. Rename columns for consistency\n",
    "4. Filter to match freight data date range\n",
    "5. Handle missing values (marked as empty strings in EIA data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35447936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING CRUDE OIL PRICE DATA\n",
      "======================================================================\n",
      "\n",
      "Requesting data from 2018-01-05 to 2025-08-22\n",
      "\n",
      "--- Loading WTI from EIA DCOILWTICO.csv ---\n",
      "Error: The file 'data/DCOILWTICO.csv' was not found.\n",
      "Please ensure the DCOILWTICO.csv file is in the data folder.\n",
      "\n",
      "--- Loading Brent EU from EIA DCOILBRENTEU.csv ---\n",
      "Success: Loaded 399 days of Brent EU crude oil price data from data/DCOILBRENTEU.csv\n",
      "  Date range: 2018-01-05 to 2025-08-22\n",
      "  Price range: $15.87 to $127.44\n",
      "  Average price: $73.04\n",
      "  Removed 0 rows with missing values\n",
      "\n",
      "First 5 rows of Brent EU data:\n",
      "                  Brent_Price\n",
      "observation_date             \n",
      "2018-01-05              68.01\n",
      "2018-01-12              69.64\n",
      "2018-01-19              68.56\n",
      "2018-01-26              70.08\n",
      "2018-02-02              67.45\n",
      "\n",
      "======================================================================\n",
      "OIL DATA LOADING COMPLETE\n",
      "======================================================================\n",
      "Total WTI days: 0\n",
      "Total Brent EU days: 399\n",
      "Data sources: Synthetic\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"LOADING CRUDE OIL PRICE DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get the date range from our freight data\n",
    "start_date = df_freight.index.min().strftime('%Y-%m-%d')\n",
    "end_date = df_freight.index.max().strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"\\nRequesting data from {start_date} to {end_date}\")\n",
    "\n",
    "df_oil_wti = pd.DataFrame()\n",
    "df_oil_brent = pd.DataFrame()\n",
    "\n",
    "# Load WTI crude oil prices from EIA DCOILWTICO dataset\n",
    "print(\"\\n--- Loading WTI from EIA DCOILWTICO.csv ---\")\n",
    "\n",
    "try:\n",
    "    # Load the EIA WTI crude oil price data\n",
    "    wti_file_path = 'data/DCOILWTICO.csv'\n",
    "    df_oil_wti_raw = pd.read_csv(wti_file_path, parse_dates=['observation_date'], index_col='observation_date')\n",
    "\n",
    "    # Rename the price column for consistency\n",
    "    df_oil_wti_raw = df_oil_wti_raw.rename(columns={'DCOILWTICO': 'WTI_Price'})\n",
    "\n",
    "    # Filter to our date range\n",
    "    df_oil_wti = df_oil_wti_raw[(df_oil_wti_raw.index >= start_date) & (df_oil_wti_raw.index <= end_date)].copy()\n",
    "\n",
    "    # Handle missing values (EIA uses empty strings for missing data)\n",
    "    df_oil_wti['WTI_Price'] = pd.to_numeric(df_oil_wti['WTI_Price'], errors='coerce')\n",
    "\n",
    "    # Remove rows with missing prices\n",
    "    before_clean = len(df_oil_wti)\n",
    "    df_oil_wti.dropna(subset=['WTI_Price'], inplace=True)\n",
    "    after_clean = len(df_oil_wti)\n",
    "\n",
    "    if not df_oil_wti.empty:\n",
    "        print(f\"Success: Loaded {len(df_oil_wti)} days of WTI crude oil price data from {wti_file_path}\")\n",
    "        print(f\"  Date range: {df_oil_wti.index.min().strftime('%Y-%m-%d')} to {df_oil_wti.index.max().strftime('%Y-%m-%d')}\")\n",
    "        print(f\"  Price range: ${df_oil_wti['WTI_Price'].min():.2f} to ${df_oil_wti['WTI_Price'].max():.2f}\")\n",
    "        print(f\"  Average price: ${df_oil_wti['WTI_Price'].mean():.2f}\")\n",
    "        print(f\"  Removed {before_clean - after_clean} rows with missing values\")\n",
    "        print(\"\\nFirst 5 rows of WTI data:\")\n",
    "        print(df_oil_wti.head())\n",
    "    else:\n",
    "        print(f\"Error: No valid WTI oil price data found in date range\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{wti_file_path}' was not found.\")\n",
    "    print(\"Please ensure the DCOILWTICO.csv file is in the data folder.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: An error occurred while loading WTI data: {str(e)[:150]}\")\n",
    "\n",
    "# Load Brent EU crude oil prices from EIA DCOILBRENTEU dataset\n",
    "print(\"\\n--- Loading Brent EU from EIA DCOILBRENTEU.csv ---\")\n",
    "\n",
    "try:\n",
    "    # Load the EIA Brent EU crude oil price data\n",
    "    brent_file_path = 'data/DCOILBRENTEU.csv'\n",
    "    df_oil_brent_raw = pd.read_csv(brent_file_path, parse_dates=['observation_date'], index_col='observation_date')\n",
    "\n",
    "    # Rename the price column for consistency\n",
    "    df_oil_brent_raw = df_oil_brent_raw.rename(columns={'DCOILBRENTEU': 'Brent_Price'})\n",
    "\n",
    "    # Filter to our date range\n",
    "    df_oil_brent = df_oil_brent_raw[(df_oil_brent_raw.index >= start_date) & (df_oil_brent_raw.index <= end_date)].copy()\n",
    "\n",
    "    # Handle missing values (EIA uses empty strings for missing data)\n",
    "    df_oil_brent['Brent_Price'] = pd.to_numeric(df_oil_brent['Brent_Price'], errors='coerce')\n",
    "\n",
    "    # Remove rows with missing prices\n",
    "    before_clean = len(df_oil_brent)\n",
    "    df_oil_brent.dropna(subset=['Brent_Price'], inplace=True)\n",
    "    after_clean = len(df_oil_brent)\n",
    "\n",
    "    if not df_oil_brent.empty:\n",
    "        print(f\"Success: Loaded {len(df_oil_brent)} days of Brent EU crude oil price data from {brent_file_path}\")\n",
    "        print(f\"  Date range: {df_oil_brent.index.min().strftime('%Y-%m-%d')} to {df_oil_brent.index.max().strftime('%Y-%m-%d')}\")\n",
    "        print(f\"  Price range: ${df_oil_brent['Brent_Price'].min():.2f} to ${df_oil_brent['Brent_Price'].max():.2f}\")\n",
    "        print(f\"  Average price: ${df_oil_brent['Brent_Price'].mean():.2f}\")\n",
    "        print(f\"  Removed {before_clean - after_clean} rows with missing values\")\n",
    "        print(\"\\nFirst 5 rows of Brent EU data:\")\n",
    "        print(df_oil_brent.head())\n",
    "    else:\n",
    "        print(f\"Error: No valid Brent EU oil price data found in date range\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{brent_file_path}' was not found.\")\n",
    "    print(\"Please ensure the DCOILBRENTEU.csv file is in the data folder.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: An error occurred while loading Brent EU data: {str(e)[:150]}\")\n",
    "\n",
    "# Fallback: Create synthetic oil price data if loading failed (last resort)\n",
    "if df_oil_wti.empty and df_oil_brent.empty:\n",
    "    print(\"\\n--- Fallback: Creating synthetic placeholder data ---\")\n",
    "    print(\"Warning: No real oil data available. Creating synthetic data for demonstration.\")\n",
    "    print(\"This should only be used for testing. For production, obtain the DCOILWTICO.csv and DCOILBRENTEU.csv files.\")\n",
    "\n",
    "    # Create date range matching freight data\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "    # Create synthetic oil prices with realistic values and volatility\n",
    "    # Base price around $70-80 with random walk\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    base_price = 75.0\n",
    "    random_walk = np.random.randn(len(date_range)).cumsum() * 2  # Random walk with std=2\n",
    "    synthetic_prices = base_price + random_walk\n",
    "\n",
    "    # Clip to reasonable range (50-120)\n",
    "    synthetic_prices = np.clip(synthetic_prices, 50, 120)\n",
    "\n",
    "    df_oil_wti = pd.DataFrame({\n",
    "        'WTI_Price': synthetic_prices\n",
    "    }, index=date_range)\n",
    "    \n",
    "    df_oil_brent = pd.DataFrame({\n",
    "        'Brent_Price': synthetic_prices + np.random.randn(len(date_range)) * 2  # Slight variation\n",
    "    }, index=date_range)\n",
    "\n",
    "    print(f\"Success: Created {len(df_oil_wti)} days of synthetic WTI oil price data\")\n",
    "    print(f\"Success: Created {len(df_oil_brent)} days of synthetic Brent EU oil price data\")\n",
    "    print(f\"  Date range: {df_oil_wti.index.min().strftime('%Y-%m-%d')} to {df_oil_wti.index.max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  WTI Price range: ${df_oil_wti['WTI_Price'].min():.2f} to ${df_oil_wti['WTI_Price'].max():.2f}\")\n",
    "    print(f\"  Brent Price range: ${df_oil_brent['Brent_Price'].min():.2f} to ${df_oil_brent['Brent_Price'].max():.2f}\")\n",
    "    print(f\"  WTI Average: ${df_oil_wti['WTI_Price'].mean():.2f}\")\n",
    "    print(f\"  Brent Average: ${df_oil_brent['Brent_Price'].mean():.2f}\")\n",
    "    print(\"\\nWarning: This is SYNTHETIC data. Replace with real DCOILWTICO.csv and DCOILBRENTEU.csv data for actual predictions.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"OIL DATA LOADING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total WTI days: {len(df_oil_wti)}\")\n",
    "print(f\"Total Brent EU days: {len(df_oil_brent)}\")\n",
    "print(f\"Data sources: {'EIA DCOILWTICO & DCOILBRENTEU' if not df_oil_wti.empty and not df_oil_brent.empty else 'Synthetic'}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f759cc",
   "metadata": {},
   "source": [
    "## Step 7: Load the new \"black swan\" geopolitical disruption data\n",
    "\n",
    "We now load the new, richer BigQuery dataset that contains specific geopolitical and black swan event metrics for shipping-critical regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b00bcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING GEOPOLITICAL DISRUPTION DATA\n",
      "======================================================================\n",
      "\n",
      "--- Loading GDELT BigQuery data ---\n",
      "Error: The file 'data/gdelt_disruption_data.csv' was not found.\n",
      "Please ensure the gdelt_disruption_data.csv file is in the data folder.\n",
      "\n",
      "Expected file structure:\n",
      "  - week_start: Date column (YYYY-MM-DD format)\n",
      "  - Various disruption metrics (e.g., conflict_events, severe_incidents, avg_tone, etc.)\n",
      "\n",
      "--- Fallback: Creating synthetic placeholder data ---\n",
      "Warning: No real GDELT data available. Creating synthetic data for demonstration.\n",
      "This should only be used for testing. For production, obtain the gdelt_disruption_data.csv file.\n",
      "Success: Created 399 weeks of synthetic geopolitical disruption data\n",
      "  Date range: 2018-01-05 to 2025-08-22\n",
      "  Columns: ['conflict_events', 'severe_incidents', 'avg_tone', 'event_density', 'volatility_index']\n",
      "\n",
      "First 5 rows of synthetic GDELT data:\n",
      "            conflict_events  severe_incidents  avg_tone  event_density  \\\n",
      "2018-01-05                5                 3 -3.583051       0.239718   \n",
      "2018-01-12                4                 2 -0.418294       0.336746   \n",
      "2018-01-19                4                 3 -2.817301       0.631060   \n",
      "2018-01-26                5                 1 -2.430096       0.872242   \n",
      "2018-02-02                5                 2 -0.116028       0.140333   \n",
      "\n",
      "            volatility_index  \n",
      "2018-01-05         28.818453  \n",
      "2018-01-12          0.646436  \n",
      "2018-01-19         49.623922  \n",
      "2018-01-26         28.562599  \n",
      "2018-02-02         73.460830  \n",
      "\n",
      "Warning: This is SYNTHETIC data. Replace with real gdelt_disruption_data.csv for actual predictions.\n",
      "\n",
      "======================================================================\n",
      "GEOPOLITICAL DATA LOADING COMPLETE\n",
      "======================================================================\n",
      "Total weeks: 399\n",
      "Data source: GDELT BigQuery\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"LOADING GEOPOLITICAL DISRUPTION DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load geopolitical disruption data from GDELT BigQuery export\n",
    "print(\"\\n--- Loading GDELT BigQuery data ---\")\n",
    "\n",
    "try:\n",
    "    # Load the GDELT disruption data exported from BigQuery\n",
    "    gdelt_file_path = 'data/gdelt_disruption_data.csv'\n",
    "    df_gdelt_raw = pd.read_csv(gdelt_file_path, parse_dates=['week_start'])\n",
    "    \n",
    "    # Set the week_start as the index\n",
    "    df_gdelt = df_gdelt_raw.set_index('week_start')\n",
    "    \n",
    "    # Filter to match freight data date range\n",
    "    df_gdelt = df_gdelt[(df_gdelt.index >= start_date) & (df_gdelt.index <= end_date)].copy()\n",
    "    \n",
    "    if not df_gdelt.empty:\n",
    "        print(f\"Success: Loaded {len(df_gdelt)} weeks of geopolitical disruption data from {gdelt_file_path}\")\n",
    "        print(f\"  Date range: {df_gdelt.index.min().strftime('%Y-%m-%d')} to {df_gdelt.index.max().strftime('%Y-%m-%d')}\")\n",
    "        print(f\"  Columns: {df_gdelt.columns.tolist()}\")\n",
    "        print(\"\\nFirst 5 rows of GDELT data:\")\n",
    "        print(df_gdelt.head())\n",
    "        \n",
    "        # Display summary statistics\n",
    "        print(\"\\nSummary statistics:\")\n",
    "        print(df_gdelt.describe())\n",
    "    else:\n",
    "        print(f\"Error: No valid GDELT data found in date range\")\n",
    "        df_gdelt = pd.DataFrame()  # Empty dataframe\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{gdelt_file_path}' was not found.\")\n",
    "    print(\"Please ensure the gdelt_disruption_data.csv file is in the data folder.\")\n",
    "    print(\"\\nExpected file structure:\")\n",
    "    print(\"  - week_start: Date column (YYYY-MM-DD format)\")\n",
    "    print(\"  - Various disruption metrics (e.g., conflict_events, severe_incidents, avg_tone, etc.)\")\n",
    "    \n",
    "    # Create an empty dataframe as fallback\n",
    "    df_gdelt = pd.DataFrame()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: An error occurred while loading GDELT data: {str(e)[:150]}\")\n",
    "    df_gdelt = pd.DataFrame()\n",
    "\n",
    "# Fallback: Create synthetic geopolitical disruption data if loading failed\n",
    "if df_gdelt.empty:\n",
    "    print(\"\\n--- Fallback: Creating synthetic placeholder data ---\")\n",
    "    print(\"Warning: No real GDELT data available. Creating synthetic data for demonstration.\")\n",
    "    print(\"This should only be used for testing. For production, obtain the gdelt_disruption_data.csv file.\")\n",
    "    \n",
    "    # Create weekly date range matching freight data\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='W-FRI')  # Weekly on Fridays\n",
    "    \n",
    "    # Create synthetic disruption metrics\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    df_gdelt = pd.DataFrame({\n",
    "        'conflict_events': np.random.poisson(5, len(date_range)),  # Poisson distribution for event counts\n",
    "        'severe_incidents': np.random.poisson(2, len(date_range)),\n",
    "        'avg_tone': np.random.randn(len(date_range)) * 2 - 1,  # Negative tone indicates conflict\n",
    "        'event_density': np.random.uniform(0.1, 0.9, len(date_range)),\n",
    "        'volatility_index': np.random.uniform(0, 100, len(date_range))\n",
    "    }, index=date_range)\n",
    "    \n",
    "    print(f\"Success: Created {len(df_gdelt)} weeks of synthetic geopolitical disruption data\")\n",
    "    print(f\"  Date range: {df_gdelt.index.min().strftime('%Y-%m-%d')} to {df_gdelt.index.max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  Columns: {df_gdelt.columns.tolist()}\")\n",
    "    print(\"\\nFirst 5 rows of synthetic GDELT data:\")\n",
    "    print(df_gdelt.head())\n",
    "    print(\"\\nWarning: This is SYNTHETIC data. Replace with real gdelt_disruption_data.csv for actual predictions.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"GEOPOLITICAL DATA LOADING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total weeks: {len(df_gdelt)}\")\n",
    "print(f\"Data source: {'GDELT BigQuery' if not df_gdelt.empty else 'Synthetic'}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_step",
   "metadata": {},
   "source": [
    "## Step 8: Save all collected data\n",
    "\n",
    "Now that we have loaded and cleaned all our data sources, let's save them to CSV files for use in the next phase of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "save_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SAVING COLLECTED DATA\n",
      "======================================================================\n",
      "\n",
      "✓ Saved freight data to data/processed/freight_data.csv\n",
      "  Rows: 385, Columns: 2\n",
      "\n",
      "✓ Saved Brent oil data to data/processed/oil_brent.csv\n",
      "  Rows: 399, Columns: 1\n",
      "\n",
      "✓ Saved geopolitical data to data/processed/geopolitical_data.csv\n",
      "  Rows: 399, Columns: 5\n",
      "\n",
      "======================================================================\n",
      "DATA COLLECTION COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "All data has been collected and saved to the data/processed folder.\n",
      "Next step: Data preprocessing and feature engineering.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SAVING COLLECTED DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "# Save freight data\n",
    "freight_output = 'data/processed/freight_data.csv'\n",
    "df_freight.to_csv(freight_output)\n",
    "print(f\"\\n✓ Saved freight data to {freight_output}\")\n",
    "print(f\"  Rows: {len(df_freight)}, Columns: {len(df_freight.columns)}\")\n",
    "\n",
    "# Save WTI oil data\n",
    "if not df_oil_wti.empty:\n",
    "    wti_output = 'data/processed/oil_wti.csv'\n",
    "    df_oil_wti.to_csv(wti_output)\n",
    "    print(f\"\\n✓ Saved WTI oil data to {wti_output}\")\n",
    "    print(f\"  Rows: {len(df_oil_wti)}, Columns: {len(df_oil_wti.columns)}\")\n",
    "\n",
    "# Save Brent oil data\n",
    "if not df_oil_brent.empty:\n",
    "    brent_output = 'data/processed/oil_brent.csv'\n",
    "    df_oil_brent.to_csv(brent_output)\n",
    "    print(f\"\\n✓ Saved Brent oil data to {brent_output}\")\n",
    "    print(f\"  Rows: {len(df_oil_brent)}, Columns: {len(df_oil_brent.columns)}\")\n",
    "\n",
    "# Save geopolitical data\n",
    "if not df_gdelt.empty:\n",
    "    gdelt_output = 'data/processed/geopolitical_data.csv'\n",
    "    df_gdelt.to_csv(gdelt_output)\n",
    "    print(f\"\\n✓ Saved geopolitical data to {gdelt_output}\")\n",
    "    print(f\"  Rows: {len(df_gdelt)}, Columns: {len(df_gdelt.columns)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATA COLLECTION COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nAll data has been collected and saved to the data/processed folder.\")\n",
    "print(\"Next step: Data preprocessing and feature engineering.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
