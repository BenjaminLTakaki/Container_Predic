{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f638300",
   "metadata": {},
   "source": [
    "# Data Understanding and Feature Engineering for Container Price Prediction\n",
    "\n",
    "This notebook performs comprehensive analysis of our collected data and engineers the time-lagged features necessary for accurate time-series forecasting of container freight prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08734685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa196ddf",
   "metadata": {},
   "source": [
    "## Step 1: Load the collected data\n",
    "\n",
    "We load the cleaned freight and black swan disruption data that was prepared in the data collection notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068b580",
   "metadata": {},
   "source": [
    "## Step 1: Load the collected data\n",
    "\n",
    "We will load the datasets we saved in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84200c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load freight data\n",
    "try:\n",
    "    df_freight = pd.read_csv('collected_freight_data.csv', parse_dates=['Date'], index_col='Date')\n",
    "    print(f\"Success: Loaded freight data with {len(df_freight)} records\")\n",
    "    print(f\"  Date range: {df_freight.index.min().date()} to {df_freight.index.max().date()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: collected_freight_data.csv not found. Please run the data collection notebook first.\")\n",
    "\n",
    "# Load black swan disruption data\n",
    "try:\n",
    "    df_news = pd.read_csv('collected_news_data.csv', parse_dates=['date'], index_col='date')\n",
    "    print(f\"Success: Loaded black swan data with {len(df_news)} records\")\n",
    "    print(f\"  Date range: {df_news.index.min().date()} to {df_news.index.max().date()}\")\n",
    "    print(f\"  Features: {df_news.columns.tolist()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: collected_news_data.csv not found. Please run the data collection notebook first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4544842",
   "metadata": {},
   "source": [
    "## Step 2: Merge the datasets\n",
    "\n",
    "We perform an inner join on the date index to create a single, aligned dataframe for analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf09fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge freight and disruption data on date index\n",
    "df_combined = df_freight.join(df_news, how='inner')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATA MERGING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Combined dataset: {len(df_combined)} weeks with both freight and disruption data\")\n",
    "print(f\"Date range: {df_combined.index.min().date()} to {df_combined.index.max().date()}\")\n",
    "print(f\"Total features: {len(df_combined.columns)}\")\n",
    "print(f\"Freight features: {df_freight.columns.tolist()}\")\n",
    "print(f\"Disruption features: {df_news.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f7152",
   "metadata": {},
   "source": [
    "## Step 3: Feature Engineering - Create Prediction Target\n",
    "\n",
    "We create the target variable for our 1-week ahead prediction by shifting the Europe Base Price backward by 1 week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f5e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable: price 1 week ahead\n",
    "df_combined['price_1w_ahead'] = df_combined['Europe_Base_Price'].shift(-1)\n",
    "\n",
    "print(\"Target variable created:\")\n",
    "print(f\"  Current price: Europe_Base_Price\")\n",
    "print(f\"  Target: price_1w_ahead (shifted -1 week)\")\n",
    "print(f\"  This means we predict next week's price using current week's data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bce384",
   "metadata": {},
   "source": [
    "## Step 4: Feature Engineering - Create Time-Lagged Features\n",
    "\n",
    "This is the critical step for time-series modeling. We create lagged versions of the disruption features to capture the temporal relationships between geopolitical events and price changes.\n",
    "\n",
    "**Lag Logic for Europe-to-Shanghai Route:**\n",
    "- **Origin/Route Lags (1-3 weeks)**: Events near shipping origins/routes affect prices quickly\n",
    "  - Yemen disruption (Red Sea/Bab el-Mandeb): 1-2 weeks\n",
    "  - Egypt disruption (Suez Canal): 1 week  \n",
    "  - Europe disruption: 1 week\n",
    "  - Maritime conflicts: 1 week\n",
    "\n",
    "- **Destination Lags (4-8 weeks)**: Asia events affect return trips and equipment availability\n",
    "  - Asia disruption: 4-6 weeks\n",
    "\n",
    "- **Global Lags (1-2 weeks)**: Black swan events have immediate global impact\n",
    "  - Black swan candidates: 1-2 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5fb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged features based on shipping route timing\n",
    "print(\"Creating time-lagged features for predictive modeling...\")\n",
    "\n",
    "# Origin/Route Lags (1-3 weeks)\n",
    "if 'yemen_disruption' in df_combined.columns:\n",
    "    df_combined['yemen_disruption_lag_1w'] = df_combined['yemen_disruption'].shift(1)\n",
    "    df_combined['yemen_disruption_lag_2w'] = df_combined['yemen_disruption'].shift(2)\n",
    "\n",
    "if 'egypt_disruption' in df_combined.columns:\n",
    "    df_combined['egypt_disruption_lag_1w'] = df_combined['egypt_disruption'].shift(1)\n",
    "\n",
    "if 'europe_disruption' in df_combined.columns:\n",
    "    df_combined['europe_disruption_lag_1w'] = df_combined['europe_disruption'].shift(1)\n",
    "\n",
    "if 'maritime_conflict_events' in df_combined.columns:\n",
    "    df_combined['maritime_conflict_lag_1w'] = df_combined['maritime_conflict_events'].shift(1)\n",
    "\n",
    "# Destination Lags (4-8 weeks) - for return trip effects\n",
    "if 'asia_disruption' in df_combined.columns:\n",
    "    df_combined['asia_disruption_lag_4w'] = df_combined['asia_disruption'].shift(4)\n",
    "    df_combined['asia_disruption_lag_6w'] = df_combined['asia_disruption'].shift(6)\n",
    "\n",
    "# Global Lags (1-2 weeks)\n",
    "if 'black_swan_candidate_events' in df_combined.columns:\n",
    "    df_combined['black_swan_lag_1w'] = df_combined['black_swan_candidate_events'].shift(1)\n",
    "    df_combined['black_swan_lag_2w'] = df_combined['black_swan_candidate_events'].shift(2)\n",
    "\n",
    "print(\"Lagged features created:\")\n",
    "lag_features = [col for col in df_combined.columns if '_lag_' in col]\n",
    "print(f\"  {len(lag_features)} lagged features: {lag_features}\")\n",
    "\n",
    "# Clean dataset by dropping rows with NaN (created by shifting)\n",
    "before_clean = len(df_combined)\n",
    "df_model_data = df_combined.dropna()\n",
    "after_clean = len(df_model_data)\n",
    "\n",
    "print(f\"\\nData cleaning:\")\n",
    "print(f\"  Before: {before_clean} rows\")\n",
    "print(f\"  After dropping NaN: {after_clean} rows\")\n",
    "print(f\"  Removed {before_clean - after_clean} rows due to lagging\")\n",
    "\n",
    "print(f\"\\nFinal modeling dataset: {len(df_model_data)} rows, {len(df_model_data.columns)} features\")\n",
    "print(f\"Date range: {df_model_data.index.min().date()} to {df_model_data.index.max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49efd8a8",
   "metadata": {},
   "source": [
    "## Step 5: Time-Series Overlay Plot\n",
    "\n",
    "Create a dual-axis visualization showing the relationship between Europe Base Price and key disruption features over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f91470",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "# Primary axis: Europe Base Price\n",
    "color1 = 'blue'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Europe Base Price (USD)', color=color1)\n",
    "ax1.plot(df_model_data.index, df_model_data['Europe_Base_Price'], color=color1, linewidth=2, label='Europe Base Price')\n",
    "ax1.tick_params(axis='y', labelcolor=color1)\n",
    "\n",
    "# Secondary axis: Key disruption features\n",
    "ax2 = ax1.twinx()\n",
    "color2 = 'red'\n",
    "ax2.set_ylabel('Disruption Events', color=color2)\n",
    "\n",
    "# Plot key disruption features\n",
    "if 'yemen_disruption' in df_model_data.columns:\n",
    "    # This is the Red Sea spike\n",
    "    ax2.plot(df_model_data.index, df_model_data['yemen_disruption'], color='red', alpha=0.7, linewidth=1.5, label='Yemen Disruption')\n",
    "\n",
    "if 'extreme_crisis_events' in df_model_data.columns:\n",
    "    # This is the COVID-19 spike\n",
    "    ax2.plot(df_model_data.index, df_model_data['extreme_crisis_events'], color='purple', alpha=0.7, linewidth=2, label='Extreme Crisis Events', linestyle='--')\n",
    "\n",
    "if 'maritime_conflict_events' in df_model_data.columns:\n",
    "    ax2.plot(df_model_data.index, df_model_data['maritime_conflict_events'], color='orange', alpha=0.7, linewidth=1.5, label='Maritime Conflicts')\n",
    "\n",
    "ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "# Title and legend\n",
    "plt.title('Europe Base Price vs Key Disruptions (Yemen & Extreme Crises)', fontsize=16, fontweight='bold')\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9)) # Add a legend\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89aa168",
   "metadata": {},
   "source": [
    "## Step 6: Predictive Correlation Heatmap\n",
    "\n",
    "This is the most important analysis - showing which lagged features are actually correlated with future price movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e29dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix for target and lagged features only\n",
    "predictive_features = ['price_1w_ahead'] + lag_features\n",
    "correlation_data = df_model_data[predictive_features].corr()\n",
    "\n",
    "# Focus on correlations with the target\n",
    "target_correlations = correlation_data['price_1w_ahead'].drop('price_1w_ahead')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PREDICTIVE FEATURE CORRELATIONS WITH FUTURE PRICE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Features ranked by correlation strength with price_1w_ahead:\")\n",
    "print(target_correlations.sort_values(ascending=False))\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_data, annot=True, cmap='coolwarm', center=0, \n",
    "            fmt='.3f', square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Predictive Correlations: Lagged Features vs Future Container Prices', fontsize=16, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INTERPRETATION GUIDE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"• Strong positive correlation (>0.5): Feature strongly predicts price increases\")\n",
    "print(\"• Strong negative correlation (<-0.5): Feature strongly predicts price decreases\") \n",
    "print(\"• Weak correlation (-0.2 to 0.2): Feature has little predictive value\")\n",
    "print(\"• Use features with |correlation| > 0.3 for modeling\")\n",
    "print(\"\\nThis heatmap validates which lagged disruption features are truly predictive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c2cd0",
   "metadata": {},
   "source": [
    "## Step 7: Time series decomposition\n",
    "\n",
    "Time series decomposition breaks down our data into three components: trend, seasonality, and residuals (random noise).\n",
    "\n",
    "### What is trend?\n",
    "\n",
    "The trend is the long-term direction of the data. Is it generally increasing, decreasing, or staying flat over time?\n",
    "\n",
    "### What is seasonality?\n",
    "\n",
    "Seasonality refers to patterns that repeat at regular intervals. For example, retail sales often spike during the holiday season every year. In shipping, we might see seasonal patterns related to manufacturing cycles or weather.\n",
    "\n",
    "### What are residuals?\n",
    "\n",
    "Residuals are what is left after removing the trend and seasonality. They represent random fluctuations and unexpected events. Large residuals might indicate unusual occurrences like port strikes or economic shocks.\n",
    "\n",
    "### Why decompose?\n",
    "\n",
    "Understanding these components separately helps us build better models. Some models are great at capturing trends, others excel at seasonality, and some handle random fluctuations well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef35f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform seasonal decomposition\n",
    "# We need at least 2 complete cycles (2 years = 104 weeks) for reliable decomposition\n",
    "if len(df_freight) >= 104:\n",
    "    print(\"Performing seasonal decomposition with yearly cycle (52 weeks)...\")\n",
    "    \n",
    "    # Decompose the Europe Base Price\n",
    "    # model='additive' assumes components add together: Value = Trend + Seasonality + Residual\n",
    "    # period=52 means we expect yearly patterns (52 weeks in a year)\n",
    "    result = seasonal_decompose(df_freight['Europe_Base_Price'], model='additive', period=52)\n",
    "    \n",
    "    # Plot the decomposition\n",
    "    fig = result.plot()\n",
    "    fig.set_size_inches(15, 10)\n",
    "    plt.suptitle('Time Series Decomposition of Europe Base Price', y=1.01, fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"- Observed: The actual price data\")\n",
    "    print(\"- Trend: The long-term movement in prices\")\n",
    "    print(\"- Seasonal: Repeating patterns within each year\")\n",
    "    print(\"- Residual: Random fluctuations and unexpected events\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Need at least 104 weeks (2 years) for reliable decomposition.\")\n",
    "    print(f\"Current data has {len(df_freight)} weeks.\")\n",
    "    print(\"Skipping decomposition.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b49347",
   "metadata": {},
   "source": [
    "## Step 7a: Seasonal Pattern Analysis and Price Impacts\n",
    "\n",
    "Understanding seasonality is crucial for our predictions. We need to identify which months or quarters typically see higher or lower prices, and quantify the typical price changes during these periods.\n",
    "\n",
    "### Why analyze seasonal impacts?\n",
    "\n",
    "**Forecasting**: Knowing seasonal patterns helps predict next week's price more accurately\n",
    "\n",
    "**Black Swan Context**: Seasonal baselines help us measure the additional impact of unexpected events\n",
    "\n",
    "**Business Planning**: Companies can anticipate when shipping costs will rise or fall\n",
    "\n",
    "### What to look for\n",
    "\n",
    "**Recurring patterns**: Do certain months consistently have higher prices?\n",
    "\n",
    "**Price amplitude**: How big are typical seasonal price swings?\n",
    "\n",
    "**Timing**: When do seasonal effects start and end?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948021e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze seasonal patterns by month and quarter\n",
    "print(\"=== Seasonal Price Analysis ===\\n\")\n",
    "\n",
    "# Extract month and quarter from dates\n",
    "df_freight['Month'] = df_freight.index.month\n",
    "df_freight['Quarter'] = df_freight.index.quarter\n",
    "\n",
    "# Calculate average price by month\n",
    "monthly_avg = df_freight.groupby('Month')['Europe_Base_Price'].agg(['mean', 'std', 'count'])\n",
    "monthly_avg.index = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                     'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "print(\"Average Europe Base Port Price by Month:\")\n",
    "print(monthly_avg)\n",
    "\n",
    "# Calculate price impact (difference from overall mean)\n",
    "overall_mean = df_freight['Europe_Base_Price'].mean()\n",
    "monthly_avg['price_impact'] = monthly_avg['mean'] - overall_mean\n",
    "monthly_avg['impact_percent'] = (monthly_avg['price_impact'] / overall_mean) * 100\n",
    "\n",
    "print(f\"\\nOverall average price: ${overall_mean:.2f}\")\n",
    "print(\"\\nMonthly Price Impacts (vs. overall average):\")\n",
    "for month in monthly_avg.index:\n",
    "    impact = monthly_avg.loc[month, 'price_impact']\n",
    "    percent = monthly_avg.loc[month, 'impact_percent']\n",
    "    direction = \"higher\" if impact > 0 else \"lower\"\n",
    "    print(f\"{month}: ${impact:+.2f} ({percent:+.1f}%) - typically {direction}\")\n",
    "\n",
    "# Visualize monthly patterns\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Monthly average prices\n",
    "axes[0].bar(monthly_avg.index, monthly_avg['mean'], color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].axhline(y=overall_mean, color='red', linestyle='--', linewidth=2, label=f'Overall Mean: ${overall_mean:.2f}')\n",
    "axes[0].set_title('Average Europe Base Port Price by Month', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Month', fontsize=12)\n",
    "axes[0].set_ylabel('Average Price (USD)', fontsize=12)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Monthly price impacts\n",
    "colors = ['green' if x < 0 else 'red' for x in monthly_avg['price_impact']]\n",
    "axes[1].bar(monthly_avg.index, monthly_avg['price_impact'], color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "axes[1].set_title('Monthly Price Impact vs. Overall Average', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Month', fontsize=12)\n",
    "axes[1].set_ylabel('Price Impact (USD)', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Quarterly analysis\n",
    "print(\"\\n=== Quarterly Price Analysis ===\\n\")\n",
    "quarterly_avg = df_freight.groupby('Quarter')['Europe_Base_Price'].agg(['mean', 'std', 'count'])\n",
    "quarterly_avg.index = ['Q1 (Jan-Mar)', 'Q2 (Apr-Jun)', 'Q3 (Jul-Sep)', 'Q4 (Oct-Dec)']\n",
    "quarterly_avg['price_impact'] = quarterly_avg['mean'] - overall_mean\n",
    "quarterly_avg['impact_percent'] = (quarterly_avg['price_impact'] / overall_mean) * 100\n",
    "\n",
    "print(\"Quarterly Price Statistics:\")\n",
    "print(quarterly_avg)\n",
    "\n",
    "print(\"\\nQuarterly Price Impacts:\")\n",
    "for quarter in quarterly_avg.index:\n",
    "    impact = quarterly_avg.loc[quarter, 'price_impact']\n",
    "    percent = quarterly_avg.loc[quarter, 'impact_percent']\n",
    "    direction = \"higher\" if impact > 0 else \"lower\"\n",
    "    print(f\"{quarter}: ${impact:+.2f} ({percent:+.1f}%) - typically {direction}\")\n",
    "\n",
    "# Clean up temporary columns\n",
    "df_freight = df_freight.drop(columns=['Month', 'Quarter'])\n",
    "\n",
    "print(\"\\n=== Key Seasonal Insights ===\")\n",
    "highest_month = monthly_avg['mean'].idxmax()\n",
    "lowest_month = monthly_avg['mean'].idxmin()\n",
    "seasonal_range = monthly_avg['mean'].max() - monthly_avg['mean'].min()\n",
    "\n",
    "print(f\"\\nHighest prices typically in: {highest_month}\")\n",
    "print(f\"Lowest prices typically in: {lowest_month}\")\n",
    "print(f\"Typical seasonal price range: ${seasonal_range:.2f}\")\n",
    "print(f\"\\nThese patterns help predict next week's price by accounting for\")\n",
    "print(f\"the time of year and typical seasonal fluctuations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e9c4f6",
   "metadata": {},
   "source": [
    "## Step 7: Summary and Next Steps\n",
    "\n",
    "Review the engineered features and prepare for model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd6573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nModeling Dataset Ready:\")\n",
    "print(f\"  • {len(df_model_data)} training samples\")\n",
    "print(f\"  • {len(lag_features)} predictive lagged features\")\n",
    "print(f\"  • Target: price_1w_ahead (1-week ahead prediction)\")\n",
    "\n",
    "print(f\"\\nKey Features Engineered:\")\n",
    "print(f\"  • Origin/Route lags: Yemen, Egypt, Europe, Maritime conflicts (1-2 weeks)\")\n",
    "print(f\"  • Destination lags: Asia disruption (4-6 weeks)\")\n",
    "print(f\"  • Global lags: Black swan events (1-2 weeks)\")\n",
    "\n",
    "print(f\"\\nTop Predictive Features:\")\n",
    "top_features = target_correlations.abs().sort_values(ascending=False).head(5)\n",
    "for feature, corr in top_features.items():\n",
    "    direction = \"increases\" if target_correlations[feature] > 0 else \"decreases\"\n",
    "    print(f\"  • {feature}: {target_correlations[feature]:.3f} (predicts price {direction})\")\n",
    "\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"  • Proceed to model development notebook (03_model_development.ipynb)\")\n",
    "print(f\"  • Train time-series models (LSTM, XGBoost) using df_model_data\")\n",
    "print(f\"  • Focus on top correlated lagged features\")\n",
    "print(f\"  • Validate predictions on holdout test set\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7764123",
   "metadata": {},
   "source": [
    "## Step 8: Stationarity test\n",
    "\n",
    "Stationarity is a property where the statistical properties of a time series (like mean and variance) do not change over time.\n",
    "\n",
    "### Why does stationarity matter?\n",
    "\n",
    "Many time series models assume the data is stationary. If it is not stationary, the model might make poor predictions. Non-stationary data often has trends or changing variance that need to be addressed.\n",
    "\n",
    "### What is the Augmented Dickey-Fuller (ADF) test?\n",
    "\n",
    "The ADF test is a statistical test that checks whether a time series is stationary. It gives us a test statistic and a p-value.\n",
    "\n",
    "### How to interpret the results\n",
    "\n",
    "p-value: This is the probability that our data is non-stationary. If p-value is less than 0.05 (5%), we can be confident the data is stationary. If p-value is greater than 0.05, the data is likely non-stationary.\n",
    "\n",
    "Test statistic: We compare this to critical values. If the test statistic is more negative than the critical value, the data is likely stationary.\n",
    "\n",
    "### What if data is non-stationary?\n",
    "\n",
    "We can make it stationary through differencing (subtracting consecutive values) or detrending (removing the trend component)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90daf4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stationarity(timeseries, column_name):\n",
    "    print(f\"\\n=== Stationarity Analysis for {column_name} ===\")\n",
    "    \n",
    "    # Calculate rolling statistics\n",
    "    # Rolling mean and std over 12 weeks (about 3 months)\n",
    "    window = 12\n",
    "    rolling_mean = timeseries.rolling(window).mean()\n",
    "    rolling_std = timeseries.rolling(window).std()\n",
    "\n",
    "    # Plot the data with rolling statistics\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(timeseries, color='blue', label='Original', linewidth=1.5)\n",
    "    plt.plot(rolling_mean, color='red', label=f'Rolling Mean ({window} weeks)', linewidth=2)\n",
    "    plt.plot(rolling_std, color='black', label=f'Rolling Std Dev ({window} weeks)', linewidth=2)\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(f'Rolling Statistics for {column_name}', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Perform Augmented Dickey-Fuller test\n",
    "    print('\\nAugmented Dickey-Fuller Test Results:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    \n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', 'Lags Used', 'Number of Observations'])\n",
    "    \n",
    "    print(dfoutput)\n",
    "    \n",
    "    print('\\nCritical Values:')\n",
    "    for key, value in dftest[4].items():\n",
    "        print(f'  {key}: {value:.3f}')\n",
    "    \n",
    "    # Interpretation\n",
    "    print('\\nInterpretation:')\n",
    "    if dfoutput['p-value'] <= 0.05:\n",
    "        print(f\"  p-value = {dfoutput['p-value']:.4f} (less than 0.05)\")\n",
    "        print(\"  Result: The series is likely STATIONARY.\")\n",
    "        print(\"  This means the statistical properties are stable over time.\")\n",
    "    else:\n",
    "        print(f\"  p-value = {dfoutput['p-value']:.4f} (greater than 0.05)\")\n",
    "        print(\"  Result: The series is likely NON-STATIONARY.\")\n",
    "        print(\"  This means it has trends or changing variance that may need addressing.\")\n",
    "\n",
    "# Check stationarity for Europe Base Price\n",
    "check_stationarity(df_freight['Europe_Base_Price'], 'Europe Base Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b7941a",
   "metadata": {},
   "source": [
    "## Step 9: Correlation analysis\n",
    "\n",
    "Correlation measures how strongly two variables are related to each other.\n",
    "\n",
    "### What is correlation?\n",
    "\n",
    "Correlation values range from -1 to +1. A value of +1 means perfect positive correlation (when one goes up, the other goes up). A value of -1 means perfect negative correlation (when one goes up, the other goes down). A value of 0 means no correlation.\n",
    "\n",
    "### Why check correlations?\n",
    "\n",
    "Understanding correlations helps us identify which variables might be useful for predicting our target variable (Europe Base Price). Strong correlations suggest that a variable contains information relevant to our prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3322272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df_freight.corr()\n",
    "\n",
    "print(\"=== Correlation Matrix ===\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualize correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            fmt='.2f', square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation Guide:\")\n",
    "print(\"- Values close to +1: Strong positive correlation\")\n",
    "print(\"- Values close to -1: Strong negative correlation\")\n",
    "print(\"- Values close to 0: Little to no correlation\")\n",
    "print(\"\\nCorrelation with Europe Base Price:\")\n",
    "print(correlation_matrix['Europe_Base_Price'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e239d",
   "metadata": {},
   "source": [
    "## Step 10: Analyze oil price relationship (if available)\n",
    "\n",
    "If we have oil price data, we can examine how it relates to container prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e43da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_oil:\n",
    "    print(\"=== Oil Price Analysis ===\")\n",
    "    print(f\"Oil data: {len(df_oil)} days\")\n",
    "    print(f\"\\nOil price statistics:\")\n",
    "    print(df_oil['Oil_Price'].describe())\n",
    "    \n",
    "    # Plot oil prices over time\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(df_oil.index, df_oil['Oil_Price'], linewidth=1.5, color='brown')\n",
    "    plt.title('Brent Crude Oil Prices Over Time', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Price (USD per barrel)', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No oil price data available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d81852f",
   "metadata": {},
   "source": [
    "## Step 12: Analyze GDELT geopolitical disruption data (if available)\n",
    "\n",
    "If we have GDELT disruption data, we can examine how geopolitical events relate to container prices.\n",
    "\n",
    "### What is the disruption index?\n",
    "\n",
    "The disruption index is a composite metric combining:\n",
    "- **Severe events** (weight 3.0): Events with strong negative impact (GoldsteinScale < -3)\n",
    "- **Conflict events** (weight 2.0): Military/violent events (QuadClass 3,4)\n",
    "- **Media mentions** (weight 1.0): Volume of news coverage\n",
    "\n",
    "Higher values indicate more severe geopolitical disruptions in shipping-critical regions.\n",
    "\n",
    "### Geographic focus\n",
    "\n",
    "Our GDELT data focuses on countries critical to global shipping routes:\n",
    "- **Choke points**: Egypt (Suez Canal), Yemen (Bab-el-Mandeb Strait)\n",
    "- **Major ports**: China, Singapore, Netherlands, Germany\n",
    "- **Geopolitical risks**: Iran, Israel, Taiwan, Ukraine, Russia\n",
    "\n",
    "### What to look for\n",
    "\n",
    "- **Correlation with prices**: Do disruptions precede price increases?\n",
    "- **Major events**: Can we identify historical black swan events (COVID-19, Suez blockage, wars)?\n",
    "- **Sentiment patterns**: How does media tone relate to price movements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d42850",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_news:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"GDELT GEOPOLITICAL DISRUPTION ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nGDELT data: {len(df_news)} weekly records\")\n",
    "    print(f\"Date range: {df_news.index.min().strftime('%Y-%m-%d')} to {df_news.index.max().strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    print(\"\\n=== Disruption Metrics Statistics ===\")\n",
    "    print(df_news.describe())\n",
    "    \n",
    "    # Disruption index over time\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Disruption index\n",
    "    axes[0].plot(df_news.index, df_news['disruption_index'], linewidth=1.5, color='red', alpha=0.7)\n",
    "    axes[0].fill_between(df_news.index, 0, df_news['disruption_index'], alpha=0.3, color='red')\n",
    "    axes[0].set_title('Geopolitical Disruption Index Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Date', fontsize=12)\n",
    "    axes[0].set_ylabel('Disruption Index', fontsize=12)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Highlight major disruption weeks (top 5%)\n",
    "    threshold_95 = df_news['disruption_index'].quantile(0.95)\n",
    "    major_disruptions = df_news[df_news['disruption_index'] > threshold_95]\n",
    "    axes[0].scatter(major_disruptions.index, major_disruptions['disruption_index'], \n",
    "                   color='darkred', s=100, alpha=0.8, label=f'Major disruptions (top 5%)', zorder=5)\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Plot 2: Media sentiment (tone)\n",
    "    axes[1].plot(df_news.index, df_news['tone'], linewidth=1.5, color='blue')\n",
    "    axes[1].axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5, label='Neutral tone')\n",
    "    axes[1].fill_between(df_news.index, 0, df_news['tone'], \n",
    "                        where=df_news['tone'] > 0, alpha=0.3, color='green', label='Positive')\n",
    "    axes[1].fill_between(df_news.index, 0, df_news['tone'], \n",
    "                        where=df_news['tone'] <= 0, alpha=0.3, color='red', label='Negative')\n",
    "    axes[1].set_title('Media Sentiment (Tone) Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Date', fontsize=12)\n",
    "    axes[1].set_ylabel('Average Tone', fontsize=12)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Event counts over time\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Plot 1: Conflict and severe events\n",
    "    axes[0].plot(df_news.index, df_news['conflict_count'], linewidth=1.5, color='orange', \n",
    "                label='Conflict events', alpha=0.8)\n",
    "    axes[0].plot(df_news.index, df_news['severe_event_count'], linewidth=1.5, color='red', \n",
    "                label='Severe events', alpha=0.8)\n",
    "    axes[0].set_title('Conflict and Severe Events Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Date', fontsize=12)\n",
    "    axes[0].set_ylabel('Event Count', fontsize=12)\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Media mentions\n",
    "    axes[1].plot(df_news.index, df_news['media_mentions'], linewidth=1.5, color='purple')\n",
    "    axes[1].fill_between(df_news.index, 0, df_news['media_mentions'], alpha=0.3, color='purple')\n",
    "    axes[1].set_title('Media Mentions Volume Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Date', fontsize=12)\n",
    "    axes[1].set_ylabel('Total Mentions', fontsize=12)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Identify and display top disruption weeks\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"TOP 15 DISRUPTION WEEKS (Historical Black Swan Events)\")\n",
    "    print(\"=\" * 70)\n",
    "    top_disruptions = df_news.nlargest(15, 'disruption_index')[\n",
    "        ['disruption_index', 'conflict_count', 'severe_event_count', 'tone', 'media_mentions']\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n{:<12} {:<12} {:<10} {:<10} {:<8} {:<12}\".format(\n",
    "        'Date', 'Disruption', 'Conflicts', 'Severe', 'Tone', 'Media'))\n",
    "    print(\"-\" * 70)\n",
    "    for date, row in top_disruptions.iterrows():\n",
    "        print(\"{:<12} {:<12.2f} {:<10.0f} {:<10.0f} {:<8.2f} {:<12.0f}\".format(\n",
    "            date.strftime('%Y-%m-%d'),\n",
    "            row['disruption_index'],\n",
    "            row['conflict_count'],\n",
    "            row['severe_event_count'],\n",
    "            row['tone'],\n",
    "            row['media_mentions']\n",
    "        ))\n",
    "    \n",
    "    # Historical context for major events\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"HISTORICAL CONTEXT\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nExpected major events in this timeframe (2018-2025):\")\n",
    "    print(\"  - COVID-19 pandemic (2020-2021): Supply chain disruptions\")\n",
    "    print(\"  - Suez Canal blockage (March 2021): Ever Given incident\")\n",
    "    print(\"  - Russia-Ukraine war (Feb 2022-present): Grain exports, fuel prices\")\n",
    "    print(\"  - Israel-Hamas conflict (Oct 2023-present): Red Sea shipping disruptions\")\n",
    "    print(\"\\nCheck if these events appear in the top disruption weeks above.\")\n",
    "    \n",
    "    # Distribution of disruption index\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(df_news['disruption_index'], bins=50, color='red', alpha=0.7, edgecolor='black')\n",
    "    plt.axvline(df_news['disruption_index'].mean(), color='blue', linestyle='--', \n",
    "                linewidth=2, label=f'Mean: {df_news[\"disruption_index\"].mean():.2f}')\n",
    "    plt.axvline(df_news['disruption_index'].median(), color='green', linestyle='--', \n",
    "                linewidth=2, label=f'Median: {df_news[\"disruption_index\"].median():.2f}')\n",
    "    plt.axvline(threshold_95, color='darkred', linestyle='--', \n",
    "                linewidth=2, label=f'95th percentile: {threshold_95:.2f}')\n",
    "    plt.title('Distribution of Disruption Index', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Disruption Index', fontsize=12)\n",
    "    plt.ylabel('Frequency (Count)', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n=== Disruption Index Statistics ===\")\n",
    "    print(f\"Mean: {df_news['disruption_index'].mean():.3f}\")\n",
    "    print(f\"Median: {df_news['disruption_index'].median():.3f}\")\n",
    "    print(f\"Std Dev: {df_news['disruption_index'].std():.3f}\")\n",
    "    print(f\"95th percentile: {threshold_95:.3f}\")\n",
    "    print(f\"\\nWeeks above 95th percentile: {len(major_disruptions)} ({len(major_disruptions)/len(df_news)*100:.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"No GDELT disruption data available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfa6f87",
   "metadata": {},
   "source": [
    "## Step 13: Correlation between disruptions and container prices\n",
    "\n",
    "Let's examine how geopolitical disruptions correlate with container price changes. This helps us understand whether disruption indicators are useful predictive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5994aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_news:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"DISRUPTION-PRICE CORRELATION ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Merge freight and disruption data on weekly dates\n",
    "    # Both datasets should already be weekly aligned (Fridays)\n",
    "    df_combined = df_freight.join(df_news, how='inner')\n",
    "    \n",
    "    print(f\"\\nCombined dataset: {len(df_combined)} weeks with both freight and disruption data\")\n",
    "    print(f\"Date range: {df_combined.index.min().strftime('%Y-%m-%d')} to {df_combined.index.max().strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    disruption_cols = ['disruption_index', 'tone', 'conflict_count', 'severe_event_count', 'media_mentions']\n",
    "    price_cols = ['Europe_Base_Price', 'SCFI_Index']\n",
    "    \n",
    "    correlation_subset = df_combined[price_cols + disruption_cols].corr()\n",
    "    \n",
    "    print(\"\\n=== Correlation Matrix ===\")\n",
    "    print(correlation_subset)\n",
    "    \n",
    "    # Visualize correlation heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_subset, annot=True, cmap='coolwarm', center=0, \n",
    "                fmt='.3f', square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation: Container Prices vs Disruption Indicators', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Focus on Europe Base Price correlations\n",
    "    print(\"\\n=== Correlation with Europe Base Price ===\")\n",
    "    price_corr = correlation_subset['Europe_Base_Price'][disruption_cols].sort_values(ascending=False)\n",
    "    print(price_corr)\n",
    "    \n",
    "    print(\"\\n=== Interpretation ===\")\n",
    "    for feature, corr_value in price_corr.items():\n",
    "        if abs(corr_value) > 0.5:\n",
    "            strength = \"STRONG\"\n",
    "        elif abs(corr_value) > 0.3:\n",
    "            strength = \"MODERATE\"\n",
    "        elif abs(corr_value) > 0.1:\n",
    "            strength = \"WEAK\"\n",
    "        else:\n",
    "            strength = \"NEGLIGIBLE\"\n",
    "        \n",
    "        direction = \"positive\" if corr_value > 0 else \"negative\"\n",
    "        print(f\"  {feature}: {strength} {direction} correlation ({corr_value:.3f})\")\n",
    "    \n",
    "    # Scatter plots: Disruption index vs Price\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Scatter 1: Disruption index vs Europe Base Price\n",
    "    axes[0].scatter(df_combined['disruption_index'], df_combined['Europe_Base_Price'], \n",
    "                   alpha=0.5, s=50, color='red')\n",
    "    axes[0].set_xlabel('Disruption Index', fontsize=12)\n",
    "    axes[0].set_ylabel('Europe Base Price (USD)', fontsize=12)\n",
    "    axes[0].set_title(f'Disruption Index vs Price\\nCorrelation: {price_corr[\"disruption_index\"]:.3f}', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(df_combined['disruption_index'], df_combined['Europe_Base_Price'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[0].plot(df_combined['disruption_index'], p(df_combined['disruption_index']), \n",
    "                \"r--\", alpha=0.8, linewidth=2, label='Trend line')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Scatter 2: Media tone vs Europe Base Price\n",
    "    axes[1].scatter(df_combined['tone'], df_combined['Europe_Base_Price'], \n",
    "                   alpha=0.5, s=50, color='blue')\n",
    "    axes[1].set_xlabel('Media Tone (Sentiment)', fontsize=12)\n",
    "    axes[1].set_ylabel('Europe Base Price (USD)', fontsize=12)\n",
    "    axes[1].set_title(f'Media Tone vs Price\\nCorrelation: {price_corr[\"tone\"]:.3f}', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add trend line\n",
    "    z2 = np.polyfit(df_combined['tone'], df_combined['Europe_Base_Price'], 1)\n",
    "    p2 = np.poly1d(z2)\n",
    "    axes[1].plot(df_combined['tone'], p2(df_combined['tone']), \n",
    "                \"b--\", alpha=0.8, linewidth=2, label='Trend line')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Lagged correlation analysis (check if disruptions predict future prices)\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"LAGGED CORRELATION ANALYSIS (Do disruptions predict future prices?)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    lags = [0, 1, 2, 3, 4]  # Check 0-4 week lags\n",
    "    lag_correlations = {}\n",
    "    \n",
    "    for lag in lags:\n",
    "        if lag == 0:\n",
    "            lag_corr = df_combined['disruption_index'].corr(df_combined['Europe_Base_Price'])\n",
    "        else:\n",
    "            lag_corr = df_combined['disruption_index'].corr(df_combined['Europe_Base_Price'].shift(-lag))\n",
    "        lag_correlations[lag] = lag_corr\n",
    "    \n",
    "    print(\"\\nDisruption index correlation with future prices:\")\n",
    "    for lag, corr in lag_correlations.items():\n",
    "        if lag == 0:\n",
    "            print(f\"  Same week (lag 0):  {corr:.3f}\")\n",
    "        else:\n",
    "            print(f\"  {lag} week(s) ahead (lag {lag}): {corr:.3f}\")\n",
    "    \n",
    "    # Plot lagged correlations\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(lags, [lag_correlations[lag] for lag in lags], marker='o', markersize=10, \n",
    "            linewidth=2, color='red')\n",
    "    plt.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    plt.xlabel('Weeks Ahead', fontsize=12)\n",
    "    plt.ylabel('Correlation with Future Price', fontsize=12)\n",
    "    plt.title('Predictive Power: Disruption Index vs Future Container Prices', \n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(lags)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find optimal lag\n",
    "    best_lag = max(lag_correlations, key=lag_correlations.get)\n",
    "    if best_lag == 0:\n",
    "        print(f\"\\nBest correlation is at lag 0 (same week): {lag_correlations[best_lag]:.3f}\")\n",
    "        print(\"Disruptions and prices move together, but may not be predictive.\")\n",
    "    else:\n",
    "        print(f\"\\nBest correlation is at lag {best_lag} ({best_lag} week(s) ahead): {lag_correlations[best_lag]:.3f}\")\n",
    "        print(f\"This suggests disruptions may help predict prices {best_lag} week(s) in advance.\")\n",
    "    \n",
    "else:\n",
    "    print(\"No GDELT disruption data available for correlation analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56810e36",
   "metadata": {},
   "source": [
    "## Step 11: Summary of findings\n",
    "\n",
    "Let's create a summary of what we learned about our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd1945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DATA UNDERSTANDING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n1. Dataset Overview:\")\n",
    "print(f\"   - Total weeks of freight data: {len(df_freight)}\")\n",
    "print(f\"   - Date range: {df_freight.index.min().strftime('%Y-%m-%d')} to {df_freight.index.max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"   - Number of price features: {len(df_freight.columns)}\")\n",
    "\n",
    "print(\"\\n2. Target Variable (Europe Base Price):\")\n",
    "print(f\"   - Mean: ${df_freight['Europe_Base_Price'].mean():.2f}\")\n",
    "print(f\"   - Range: ${df_freight['Europe_Base_Price'].min():.2f} to ${df_freight['Europe_Base_Price'].max():.2f}\")\n",
    "print(f\"   - Volatility (std): ${df_freight['Europe_Base_Price'].std():.2f}\")\n",
    "\n",
    "print(\"\\n3. Data Quality:\")\n",
    "missing_total = df_freight.isnull().sum().sum()\n",
    "if missing_total == 0:\n",
    "    print(\"   - No missing values in freight data\")\n",
    "else:\n",
    "    print(f\"   - Found {missing_total} missing values in freight data\")\n",
    "\n",
    "print(\"\\n4. Volatility Assessment:\")\n",
    "price_range = df_freight['Europe_Base_Price'].max() - df_freight['Europe_Base_Price'].min()\n",
    "price_volatility = df_freight['Europe_Base_Price'].std() / df_freight['Europe_Base_Price'].mean()\n",
    "print(f\"   - Price range: ${price_range:.2f}\")\n",
    "print(f\"   - Coefficient of variation: {price_volatility:.2%}\")\n",
    "\n",
    "if price_volatility > 0.3:\n",
    "    print(\"   - Prices show HIGH volatility (good for disruption modeling)\")\n",
    "elif price_volatility > 0.15:\n",
    "    print(\"   - Prices show MODERATE volatility\")\n",
    "else:\n",
    "    print(\"   - Prices show LOW volatility\")\n",
    "\n",
    "print(\"\\n5. External Data Sources:\")\n",
    "if has_oil:\n",
    "    print(f\"   Available: Oil price data: {len(df_oil)} days\")\n",
    "else:\n",
    "    print(\"   Not available: Oil price data: Not available\")\n",
    "\n",
    "if has_news:\n",
    "    print(f\"   Available: GDELT disruption data: {len(df_news)} weeks\")\n",
    "    print(f\"     - Disruption index range: {df_news['disruption_index'].min():.3f} to {df_news['disruption_index'].max():.3f}\")\n",
    "    print(f\"     - Total conflict events: {df_news['conflict_count'].sum():.0f}\")\n",
    "    print(f\"     - Total severe events: {df_news['severe_event_count'].sum():.0f}\")\n",
    "    \n",
    "    # Show correlation if data was merged\n",
    "    try:\n",
    "        if 'df_combined' in locals():\n",
    "            disruption_corr = df_combined['Europe_Base_Price'].corr(df_combined['disruption_index'])\n",
    "            print(f\"     - Correlation with prices: {disruption_corr:.3f}\")\n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    print(\"   Not available: GDELT disruption data: Not available\")\n",
    "\n",
    "print(\"\\n6. Key Observations:\")\n",
    "print(\"   - Time series data suitable for sequential modeling (LSTM, GRU)\")\n",
    "print(\"   - Weekly frequency matches business planning cycles\")\n",
    "if has_news:\n",
    "    print(\"   - Geopolitical disruption features available for black swan detection\")\n",
    "    print(\"   - Multiple disruption indicators (conflicts, sentiment, media volume)\")\n",
    "\n",
    "print(\"\\n7. Next Steps:\")\n",
    "print(\"   - Proceed to data preparation notebook (03_data_preparation.ipynb)\")\n",
    "print(\"   - Create lag features from disruption indicators\")\n",
    "print(\"   - Merge all data sources on weekly alignment\")\n",
    "print(\"   - Prepare training/test splits for 1-week ahead prediction\")\n",
    "print(\"   - Engineer additional features (rolling averages, price changes, etc.)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
